{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HG5IWpP03PMj"
   },
   "source": [
    "### Install transformers library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9377,
     "status": "ok",
     "timestamp": 1612253523864,
     "user": {
      "displayName": "ATHANASIOS BRIAKOS",
      "photoUrl": "",
      "userId": "17932687169031889732"
     },
     "user_tz": -120
    },
    "id": "uC-Kx4ij3T6a",
    "outputId": "6625ed92-6c98-4913-bbcc-75690050c1fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b1/41130a228dd656a1a31ba281598a968320283f48d42782845f6ba567f00b/transformers-4.2.2-py3-none-any.whl (1.8MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8MB 9.8MB/s \n",
      "\u001b[?25hCollecting tokenizers==0.9.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 43.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 47.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=fe7669e14ae0013282e17aae09234d172855de19979ae6aa5588978d707beb50\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAFnm5Hwt-OK"
   },
   "source": [
    "### Essential libraries imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30853,
     "status": "ok",
     "timestamp": 1612253545367,
     "user": {
      "displayName": "ATHANASIOS BRIAKOS",
      "photoUrl": "",
      "userId": "17932687169031889732"
     },
     "user_tz": -120
    },
    "id": "0cwevUPEt9s-",
    "outputId": "6bfdd04d-0686-44fc-9544-9f71579ae3d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer,BertTokenizerFast\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OsWRMwlR6DwQ"
   },
   "source": [
    "### Prepare GPU Cuda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30842,
     "status": "ok",
     "timestamp": 1612253545370,
     "user": {
      "displayName": "ATHANASIOS BRIAKOS",
      "photoUrl": "",
      "userId": "17932687169031889732"
     },
     "user_tz": -120
    },
    "id": "hN25lAzQ6Jws",
    "outputId": "f5d14616-36fb-4db2-e967-d474687bf1fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available for running: \n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device available for running: \")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BpaTHLJlfY2V"
   },
   "source": [
    "### Define tokenizer and load model that we fine tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4928,
     "status": "ok",
     "timestamp": 1612253572768,
     "user": {
      "displayName": "ATHANASIOS BRIAKOS",
      "photoUrl": "",
      "userId": "17932687169031889732"
     },
     "user_tz": -120
    },
    "id": "XRb-5aroca76",
    "outputId": "87b87e47-9c12-486a-b838-e1002ffbee90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "# tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load model that we fine tuned it\n",
    "model = torch.load(\"/content/drive/MyDrive/bert/bert_6\",map_location=torch.device('cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIwFigFzfk0x"
   },
   "source": [
    "### Declare some functions from official evaluation script of SQuAD 2.0 Dataset so as to evaluate model's answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZ4vJX_pbve4"
   },
   "outputs": [],
   "source": [
    "def get_prediction(context,question):\n",
    "\n",
    "  inputs = tokenizer.encode_plus(question, context, return_tensors='pt').to(device)\n",
    "\n",
    "  outputs = model(**inputs)\n",
    "  answer_start = torch.argmax(outputs[0])  \n",
    "  answer_end = torch.argmax(outputs[1]) + 1 \n",
    "\n",
    "  answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
    "\n",
    "  return answer\n",
    "\n",
    "def normalize_text(s):\n",
    "  \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "  import string, re\n",
    "\n",
    "  def remove_articles(text):\n",
    "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "    return re.sub(regex, \" \", text)\n",
    "\n",
    "  def white_space_fix(text):\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "  def remove_punc(text):\n",
    "    exclude = set(string.punctuation)\n",
    "    return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "  def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "  return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "  pred_tokens = normalize_text(prediction).split()\n",
    "  truth_tokens = normalize_text(truth).split()\n",
    "  \n",
    "  # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "  if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "    return int(pred_tokens == truth_tokens)\n",
    "  \n",
    "  common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "  \n",
    "  # if there are no common tokens then f1 = 0\n",
    "  if len(common_tokens) == 0:\n",
    "    return 0\n",
    "  \n",
    "  prec = len(common_tokens) / len(pred_tokens)\n",
    "  rec = len(common_tokens) / len(truth_tokens)\n",
    "  \n",
    "  return 2 * (prec * rec) / (prec + rec)\n",
    "  \n",
    "def query_answer(context,question,answer):\n",
    "\n",
    "  prediction = get_prediction(context,question)\n",
    "  em_score = compute_exact_match(prediction, answer)\n",
    "  f1_score = compute_f1(prediction, answer)\n",
    "\n",
    "  print(f\"Question: {question}\")\n",
    "  print(f\"Prediction: {prediction}\")\n",
    "  print(f\"True Answer: {answer}\")\n",
    "  print(f\"EM: {em_score} \\t F1: {f1_score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3uDrwUyCQ4G"
   },
   "source": [
    "```\n",
    "> In this cell, we built some functions (with help of official evaluation script of SQuAD v2, in that way to give each \n",
    "time a paragraph (context in which at most times answer is included), a specific question and it's real answer!\n",
    "```\n",
    "\n",
    "From [Question Answering on SQuAD 2.0 Dataset](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/reports/default/15848195.pdf) paper we retrieve more information about evaluation metrics:\n",
    "```\n",
    "Two evaluation metrics are employed: Exact Match (EM) score and F1 score. EM is a binary measurement of whether the \n",
    "percentage of output from a system exactly matches the ground truth answer(the proportion of questions that are \n",
    "answered in exact same words as the ground truth). F1 score is a harmonic mean of precision an recall. For each \n",
    "question, precision is calculated as the number of correctly predicted words divided by the total words in the predicted \n",
    "answer. Recall is the number of correctly predicted words divided by the number of words in the ground truth answer.\n",
    "The F1 score is averaged among questions\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBSC3kpYf0yv"
   },
   "source": [
    "### First example with Carles Puyol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3457,
     "status": "ok",
     "timestamp": 1612254890625,
     "user": {
      "displayName": "ATHANASIOS BRIAKOS",
      "photoUrl": "",
      "userId": "17932687169031889732"
     },
     "user_tz": -120
    },
    "id": "8Eh3BhgWcQqE",
    "outputId": "5da59263-2d78-471e-bb50-3d31ba378c66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many caps did Puyol win for Spain?\n",
      "Prediction: 100\n",
      "True Answer: 100\n",
      "EM: 1 \t F1: 1.0\n",
      "\n",
      "Question: How many matches Puyol appeared?\n",
      "Prediction: 593\n",
      "True Answer: 593\n",
      "EM: 1 \t F1: 1.0\n",
      "\n",
      "Question: How many matches Puyol played?\n",
      "Prediction: 593\n",
      "True Answer: 593\n",
      "EM: 1 \t F1: 1.0\n",
      "\n",
      "Question: When did Puyol retire?\n",
      "Prediction: 2014,\n",
      "True Answer: 2014\n",
      "EM: 1 \t F1: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\"Carles Puyol Saforcada, born 13 April 1978, is a Spanish retired professional footballer\n",
    "             who played his entire career for Barcelona. Mainly a central defender, he could also play in either full-back position, mostly as a right-back, and \n",
    "             is regarded as one of the best defenders of his generation and all time. He was Barcelona's captain from August 2004 until his retirement in 2014, \n",
    "             and appeared in 593 competitive matches for the club. He won 18 major club titles, including six La Liga trophies and three Champions Leagues.\n",
    "             Puyol won 100 caps for Spain, and was part of the squads that won Euro 2008 and the 2010 World Cup. In the 2010 World Cup semi-final, he scored \n",
    "             the only goal of the game against Germany.\n",
    "          \"\"\"\n",
    "\n",
    "questions = [\n",
    "             \"How many caps did Puyol win for Spain?\",\n",
    "             \"How many matches Puyol appeared?\",\n",
    "             \"How many matches Puyol played?\",\n",
    "             \"When did Puyol retire?\"]\n",
    "answers = [\"100\",\"593\",\"593\",\"2014\"]\n",
    "\n",
    "for q,a in zip(questions,answers):\n",
    "  query_answer(context,q,a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3nhrBWZ4Vya"
   },
   "source": [
    "> In short term answers, which includes numbers model was absolutely magnificent! Note that second and third question were the same with a slight difference of verb 'play' instead of 'appear', but still got it! 4/4 correct answers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZ9XV3pMf5rP"
   },
   "source": [
    "### Second example with Ioannina city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2025,
     "status": "ok",
     "timestamp": 1612253602496,
     "user": {
      "displayName": "ATHANASIOS BRIAKOS",
      "photoUrl": "",
      "userId": "17932687169031889732"
     },
     "user_tz": -120
    },
    "id": "e8ulfK0JcStH",
    "outputId": "2335a5cc-5059-420b-b18f-bf27dbc9a1b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What's population of Ioannina?\n",
      "Prediction: 100 thousand\n",
      "True Answer: 100 thousand\n",
      "EM: 1 \t F1: 1.0\n",
      "\n",
      "Question: Where is Ioannina located?\n",
      "Prediction: northwest part\n",
      "True Answer: in the northwest part of Greece\n",
      "EM: 0 \t F1: 0.5714285714285715\n",
      "\n",
      "Question: What is Ioannina?\n",
      "Prediction: beautiful city\n",
      "True Answer: city\n",
      "EM: 0 \t F1: 0.6666666666666666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\"Greece, officially the Hellenic Republic and also known as Hellas, is a country located in Southeast Europe.\n",
    "             Its population is approximately 10.7 million as of 2018; Athens is its largest and capital city, followed by Thessaloniki.\n",
    "             Situated on the southern tip of the Balkans, Greece is located at the crossroads of Europe, Asia, and Africa. \n",
    "             Another beautiful city which is located in the northwest part of Greece is Ioannina with population 100 thousand people. \n",
    "          \"\"\"\n",
    "\n",
    "questions = [\"What's population of Ioannina?\",\"Where is Ioannina located?\",\"What is Ioannina?\"]\n",
    "answers = [\"100 thousand\",\"in the northwest part of Greece\",\"city\"]\n",
    "\n",
    "for q,a in zip(questions,answers):\n",
    "  query_answer(context,q,a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFiEKEkj39YG"
   },
   "source": [
    "> Here as we can easily see our model had a brilliant performance! 3/3 correct answers! Notice that we were pretty strict with our true answers, cause we demand for example for third example to answer 'city', but model respond 'beautiful city' which was acceptable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GP4u5MOazgfQ"
   },
   "source": [
    "### Third example with Cloud Computing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4732,
     "status": "ok",
     "timestamp": 1612257836712,
     "user": {
      "displayName": "ATHANASIOS BRIAKOS",
      "photoUrl": "",
      "userId": "17932687169031889732"
     },
     "user_tz": -120
    },
    "id": "TSyh8R6czg0C",
    "outputId": "eaa06995-0841-4466-b1c4-5387234ca27a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is cloud computing?\n",
      "Prediction: on - demand availability of computer system resources,\n",
      "True Answer: on-demand availability of computer system resources\n",
      "EM: 0 \t F1: 0.7692307692307692\n",
      "\n",
      "Question: What does cloud computing allow?\n",
      "Prediction: sharing of resources to achieve coherence and economies of scale.\n",
      "True Answer: enterprises to get their applications up and running faster\n",
      "EM: 0 \t F1: 0.2105263157894737\n",
      "\n",
      "Question: What has led to growth in cloud computing?\n",
      "Prediction: \n",
      "True Answer: The availability of high-capacity networks, low-cost computers and storage devices as well as the widespread adoption of hardware virtualization, \n",
      "             service-oriented architecture and autonomic and utility computing\n",
      "EM: 0 \t F1: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\"Cloud computing is the on-demand availability of computer system resources, especially data storage (cloud storage) and computing power, without direct \n",
    "             active management by the user. The term is generally used to describe data centers available to many users over the Internet.Large clouds, predominant today, \n",
    "             often have functions distributed over multiple locations from central servers. If the connection to the user is relatively close, it may be designated an edge\n",
    "             server. Clouds may be limited to a single organization (enterprise clouds), or be available to multiple organizations (public cloud).Cloud computing relies \n",
    "             on sharing of resources to achieve coherence and economies of scale.Advocates of public and hybrid clouds note that cloud computing allows companies to avoid or \n",
    "             minimize up-front IT infrastructure costs. Proponents also claim that cloud computing allows enterprises to get their applications up and running faster, with \n",
    "             improved manageability and less maintenance, and that it enables IT teams to more rapidly adjust resources to meet fluctuating and unpredictable demand, providing \n",
    "             the burst computing capability: high computing power at certain periods of peak demand.Cloud providers typically use a \"pay-as-you-go\" model, which can lead\n",
    "             to unexpected operating expenses if administrators are not familiarized with cloud-pricing models.The availability of high-capacity networks, low-cost computers\n",
    "             and storage devices as well as the widespread adoption of hardware virtualization, service-oriented architecture and autonomic and utility computing has led to\n",
    "             growth in cloud computing.By 2019, Linux was the most widely used operating system, including in Microsoft's offerings and is thus described as dominant.\n",
    "          \"\"\"\n",
    "\n",
    "questions = [\"What is cloud computing?\",\n",
    "             \"What does cloud computing allow?\",\n",
    "             \"What has led to growth in cloud computing?\",\n",
    "             ]\n",
    "\n",
    "answers =   [\"on-demand availability of computer system resources\",\n",
    "             \"enterprises to get their applications up and running faster\",\n",
    "             \"\"\"The availability of high-capacity networks, low-cost computers and storage devices as well as the widespread adoption of hardware virtualization, \n",
    "             service-oriented architecture and autonomic and utility computing\"\"\",\n",
    "             ]\n",
    "\n",
    "for q,a in zip(questions,answers):\n",
    "  query_answer(context,q,a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZiI8yH223EI"
   },
   "source": [
    "> As we can observe, although our model found the answer to our first question...our two last answers were wrong! So when we ask more complicated questions (without a normal sentence structure) our model doesn't perform so well! Note that in our last question model predicted that answer doesn't exist! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duwxeP6PDlsw"
   },
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqM3tKGUDodm"
   },
   "source": [
    "\n",
    "> Despite the fact that our model was overfitting and we didn't make it to avoid this phenomenon, it still had a pretty \n",
    "descent performance. More specifically through our three examples we noticed that model did absolutely amazing work when\n",
    "questions had as answers numbers or sentece's structure was simple. In our last example, we tried to make its work difficult\n",
    "and it had some wrong results. Note that if you load a pretrained model (fine tuned bert for example you are going to \n",
    "have generally speaking better behavior to your examples) and that due to the fact that model has been fine tuned by \n",
    "experts with more data and with more computing power in their hands. You can check this behavior of \n",
    "'bert-large-uncased-whole-word-masking-finetuned-squad' model in the next notebook, called 'CompareWithBertFineTunedSQuAD'.\n",
    "\n",
    "> All these which we mentioned above were notes which we conclude given that question answering is one of the most challenging\n",
    "tasks in Natural Languages Processing, where the machine tries to comprehend a given passage of text and correctly gives \n",
    "an answer to the questions.\n",
    "\n",
    "> Last but not least, note that our contexts and questions are really irrelevant with SQuAD dataset's examples, with which we fine tuned our model, thus makes our correct answers more remarkable!\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BertEvaluation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
